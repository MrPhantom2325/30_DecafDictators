{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT2wFxS3dxdrybe4TFD1f/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrPhantom2325/30_DecafDictators/blob/main/Final_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import flask\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import threading\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "from PyPDF2 import PdfReader\n",
        "import torch\n",
        "import io\n",
        "import base64\n",
        "from pyngrok import ngrok\n",
        "\n",
        "class BloodTestAnalyzer:\n",
        "    def __init__(self, pdf_path, api_key, cx):\n",
        "        # Google Custom Search API credentials\n",
        "        self.api_key = api_key\n",
        "        self.cx = cx\n",
        "\n",
        "        # Load QA model\n",
        "        self.qa_model = pipeline(\n",
        "            \"question-answering\",\n",
        "            model=\"deepset/roberta-base-squad2\"\n",
        "        )\n",
        "\n",
        "        # Load generative model\n",
        "        try:\n",
        "            self.medical_model = AutoModelForCausalLM.from_pretrained(\"microsoft/biogpt\")\n",
        "            self.medical_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
        "        except:\n",
        "            self.medical_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "            self.medical_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "        # Process PDF\n",
        "        self.pdf_path = pdf_path\n",
        "        self.pdf_text = self.extract_text_from_pdf()\n",
        "        self.parameters = self.extract_parameters_and_values()\n",
        "        self.ranges = self.extract_parameter_ranges()\n",
        "\n",
        "    def extract_text_from_pdf(self):\n",
        "        \"\"\"Extract text from PDF file\"\"\"\n",
        "        try:\n",
        "            reader = PdfReader(self.pdf_path)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text()\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting PDF text: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_parameters_and_values(self):\n",
        "        \"\"\"Extract parameters and their values from PDF text\"\"\"\n",
        "        # More flexible parameter extraction\n",
        "        pattern = r'(\\w+(?:\\s+\\w+)?)\\s+(\\d+\\.?\\d*)\\s*([a-zA-Z/]+)?'\n",
        "        matches = re.findall(pattern, self.pdf_text)\n",
        "\n",
        "        parameters = []\n",
        "        for match in matches:\n",
        "            param, value, unit = match\n",
        "            try:\n",
        "                numeric_value = float(value)\n",
        "                parameters.append({\n",
        "                    'name': param.strip(),\n",
        "                    'value': numeric_value,\n",
        "                    'unit': unit or ''\n",
        "                })\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        return parameters\n",
        "\n",
        "    def extract_parameter_ranges(self):\n",
        "        \"\"\"Dynamically extract reference ranges from PDF text\"\"\"\n",
        "        ranges = {}\n",
        "\n",
        "        # Look for range patterns in the text\n",
        "        range_patterns = [\n",
        "            r'(\\w+(?:\\s+\\w+)?)\\s*:\\s*(\\d+\\.?\\d*)\\s*-\\s*(\\d+\\.?\\d*)',  # \"Parameter: low - high\"\n",
        "            r'Normal\\s+Range\\s*:\\s*(\\w+(?:\\s+\\w+)?)\\s*(\\d+\\.?\\d*)\\s*-\\s*(\\d+\\.?\\d*)'  # \"Normal Range: Parameter low - high\"\n",
        "        ]\n",
        "\n",
        "        for pattern in range_patterns:\n",
        "            matches = re.findall(pattern, self.pdf_text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                try:\n",
        "                    # Handle different match structures\n",
        "                    if len(match) == 3:\n",
        "                        param, low, high = match\n",
        "                    else:\n",
        "                        param, low, high = match[1], match[2], match[3]\n",
        "\n",
        "                    param = param.strip().upper()\n",
        "                    ranges[param] = {\n",
        "                        'low': float(low),\n",
        "                        'high': float(high)\n",
        "                    }\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "        # Fallback to predefined ranges if no ranges found\n",
        "        if not ranges:\n",
        "            ranges = {\n",
        "                'HAEMOGLOBIN': {'low': 12, 'high': 15},\n",
        "                'RBC COUNT': {'low': 3.8, 'high': 4.8},\n",
        "            }\n",
        "\n",
        "        return ranges\n",
        "\n",
        "    def google_search(self, query):\n",
        "        \"\"\"\n",
        "        Search Google using the Custom Search JSON API.\n",
        "        \"\"\"\n",
        "        url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={self.api_key}&cx={self.cx}\"\n",
        "        try:\n",
        "            response = requests.get(url).json()\n",
        "            results = [item.get('snippet', '') for item in response.get('items', [])]\n",
        "            return results[:3]  # Return top 3 snippets\n",
        "        except Exception as e:\n",
        "            return [f\"Error fetching data from Google: {e}\"]\n",
        "\n",
        "    def generate_medical_insight(self, parameter, status, value):\n",
        "        \"\"\"\n",
        "        Generate detailed medical insights with Google Search for additional context\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Construct a specific query about the parameter and its health implications\n",
        "            query = f\"Health implications of {parameter} being {status} normal range (value {value})\"\n",
        "\n",
        "            # Perform Google Search\n",
        "            search_results = self.google_search(query)\n",
        "\n",
        "            # Combine search results into a comprehensive insight\n",
        "            google_insights = \" \".join(search_results)\n",
        "\n",
        "            # Generate a base medical insight\n",
        "            base_insight = (\n",
        "                f\"Your {parameter} is {status} the normal range. \"\n",
        "                f\"Current value: {value}. \"\n",
        "            )\n",
        "\n",
        "            # Analyze potential implications\n",
        "            if status == \"below\":\n",
        "                implication = (\n",
        "                    f\"Low {parameter} levels may indicate potential health concerns such as \"\n",
        "                    \"nutrient deficiency, anemia, or underlying medical conditions. \"\n",
        "                )\n",
        "            elif status == \"above\":\n",
        "                implication = (\n",
        "                    f\"High {parameter} levels could suggest potential health issues like \"\n",
        "                    \"inflammation, infection, or metabolic disorders. \"\n",
        "                )\n",
        "            else:\n",
        "                implication = \"Your parameter is within the normal range, which is a good sign. \"\n",
        "\n",
        "            # Combine insights\n",
        "            full_insight = base_insight + implication\n",
        "\n",
        "            # Append Google search insights\n",
        "            if google_insights:\n",
        "                full_insight += f\"\\n\\nAdditional Insights: {google_insights}\"\n",
        "\n",
        "            return full_insight\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Could not generate medical insight: {str(e)}\"\n",
        "\n",
        "    def analyze_parameters(self):\n",
        "        \"\"\"Comprehensive analysis of blood test parameters\"\"\"\n",
        "        analysis_results = {}\n",
        "\n",
        "        for param in self.parameters:\n",
        "            name = param['name'].upper()\n",
        "            value = param['value']\n",
        "\n",
        "            # Check if parameter exists in ranges\n",
        "            if name in self.ranges:\n",
        "                range_info = self.ranges[name]\n",
        "\n",
        "                # Determine status\n",
        "                if value < range_info['low']:\n",
        "                    status = \"below\"\n",
        "                elif value > range_info['high']:\n",
        "                    status = \"above\"\n",
        "                else:\n",
        "                    status = \"within\"\n",
        "\n",
        "                # Generate medical insight with detailed analysis\n",
        "                insight = self.generate_medical_insight(name, status, value)\n",
        "\n",
        "                # Create analysis entry\n",
        "                analysis_results[name] = {\n",
        "                    'value': value,\n",
        "                    'status': status,\n",
        "                    'range': f\"{range_info['low']}-{range_info['high']}\",\n",
        "                    'insight': insight\n",
        "                }\n",
        "\n",
        "        return analysis_results\n",
        "\n",
        "    def interactive_chatbot(self):\n",
        "        \"\"\"Enhanced interactive medical chatbot with comprehensive PDF querying\"\"\"\n",
        "        print(\"\\n🩺 Medical Report Chatbot 🩺\")\n",
        "        print(\"Ask questions about your blood test or health. Type 'quit' to exit.\")\n",
        "\n",
        "        while True:\n",
        "            # Get user input\n",
        "            user_input = input(\"\\n> Your Question: \").lower()\n",
        "\n",
        "            # Exit condition\n",
        "            if user_input in ['quit', 'exit', 'bye']:\n",
        "                print(\"Thank you for using the Medical Report Chatbot. Stay healthy!\")\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                # Improved PDF text search\n",
        "                # Add more flexible matching\n",
        "                pdf_matches = re.findall(r'\\b' + re.escape(user_input) + r'\\b', self.pdf_text, re.IGNORECASE)\n",
        "\n",
        "                if pdf_matches:\n",
        "                    # If direct match found in PDF\n",
        "                    context_window = 100  # characters before and after the match\n",
        "                    detailed_context = []\n",
        "\n",
        "                    for match in pdf_matches:\n",
        "                        start = max(0, self.pdf_text.find(match) - context_window)\n",
        "                        end = min(len(self.pdf_text), self.pdf_text.find(match) + context_window)\n",
        "                        context = self.pdf_text[start:end]\n",
        "                        detailed_context.append(context.strip())\n",
        "\n",
        "                    print(\"\\n🩺 PDF Report Insights:\")\n",
        "                    for context in detailed_context:\n",
        "                        print(f\"- {context}\")\n",
        "\n",
        "                # QA model fallback\n",
        "                qa_response = self.qa_model(\n",
        "                    question=user_input,\n",
        "                    context=self.pdf_text\n",
        "                )\n",
        "\n",
        "                if qa_response['answer'] and qa_response['score'] > 0.4:\n",
        "                    print(\"\\n🤖 Direct Answer:\")\n",
        "                    print(f\"{qa_response['answer']} (Confidence: {qa_response['score']:.2f})\")\n",
        "\n",
        "                # If no good PDF answer, try Google Search\n",
        "                if not pdf_matches and (not qa_response['answer'] or qa_response['score'] < 0.4):\n",
        "                    google_results = self.google_search(user_input)\n",
        "\n",
        "                    print(\"\\n🌐 Additional Insights:\")\n",
        "                    for i, result in enumerate(google_results, 1):\n",
        "                        print(f\"{i}. {result}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing your question: {e}\")\n",
        "\n",
        "    def display_full_report(self):\n",
        "        \"\"\"Display comprehensive blood test report\"\"\"\n",
        "        print(\"\\n🩸 Comprehensive Blood Test Report 🩸\")\n",
        "\n",
        "        # Analyze parameters\n",
        "        analysis = self.analyze_parameters()\n",
        "\n",
        "        # Display detailed analysis\n",
        "        for param, details in analysis.items():\n",
        "            print(f\"\\n{param}:\")\n",
        "            print(f\"  Value: {details['value']}\")\n",
        "            print(f\"  Status: {details['status']} normal range\")\n",
        "            print(f\"  Reference Range: {details['range']}\")\n",
        "            print(f\"  Medical Insight: {details['insight']}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Global variable to store the analyzer\n",
        "global_analyzer = None\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_pdf():\n",
        "    global global_analyzer\n",
        "\n",
        "    try:\n",
        "        # Get base64 encoded PDF\n",
        "        pdf_base64 = request.json.get('pdf', '')\n",
        "\n",
        "        # Decode base64 PDF\n",
        "        pdf_bytes = base64.b64decode(pdf_base64)\n",
        "\n",
        "        # Create a file-like object\n",
        "        pdf_file = io.BytesIO(pdf_bytes)\n",
        "\n",
        "        # Extract text from PDF\n",
        "        reader = PdfReader(pdf_file)\n",
        "        pdf_text = \"\"\n",
        "        for page in reader.pages:\n",
        "            pdf_text += page.extract_text()\n",
        "\n",
        "        # Initialize analyzer\n",
        "        api_key = \"AIzaSyC12bLtgjDllE8h4ew8KxKkqHLCMWeKNkU\"\n",
        "        cx = \"c3d4dc32c9faa4b9c\"\n",
        "        global_analyzer = BloodTestAnalyzer(pdf_text, api_key, cx)\n",
        "\n",
        "        # Generate initial report\n",
        "        analysis = global_analyzer.analyze_parameters()\n",
        "\n",
        "        return jsonify({\n",
        "            'message': 'PDF processed successfully',\n",
        "            'report': analysis\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    global global_analyzer\n",
        "\n",
        "    if global_analyzer is None:\n",
        "        return jsonify({'error': 'No PDF uploaded yet'}), 400\n",
        "\n",
        "    user_input = request.json.get('message', '')\n",
        "\n",
        "    try:\n",
        "        # Perform PDF text search\n",
        "        pdf_matches = re.findall(r'\\b' + re.escape(user_input) + r'\\b', global_analyzer.pdf_text, re.IGNORECASE)\n",
        "\n",
        "        response = {\n",
        "            'pdf_matches': [],\n",
        "            'qa_response': None,\n",
        "            'google_results': []\n",
        "        }\n",
        "\n",
        "        if pdf_matches:\n",
        "            # Context extraction\n",
        "            context_window = 100\n",
        "            detailed_context = []\n",
        "\n",
        "            for match in pdf_matches:\n",
        "                start = max(0, global_analyzer.pdf_text.find(match) - context_window)\n",
        "                end = min(len(global_analyzer.pdf_text), global_analyzer.pdf_text.find(match) + context_window)\n",
        "                context = global_analyzer.pdf_text[start:end]\n",
        "                detailed_context.append(context.strip())\n",
        "\n",
        "            response['pdf_matches'] = detailed_context\n",
        "\n",
        "        # QA model fallback\n",
        "        qa_response = global_analyzer.qa_model(\n",
        "            question=user_input,\n",
        "            context=global_analyzer.pdf_text\n",
        "        )\n",
        "\n",
        "        if qa_response['answer'] and qa_response['score'] > 0.4:\n",
        "            response['qa_response'] = {\n",
        "                'answer': qa_response['answer'],\n",
        "                'confidence': qa_response['score']\n",
        "            }\n",
        "\n",
        "        # Google Search fallback\n",
        "        if not pdf_matches and (not qa_response['answer'] or qa_response['score'] < 0.4):\n",
        "            google_results = global_analyzer.google_search(user_input)\n",
        "            response['google_results'] = google_results\n",
        "\n",
        "        return jsonify(response)\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "\n",
        "ngrok.set_auth_token('2pSIzr1MNcqoBh1MV6DLE6eKNip_6ZoPPkhQqzAutrP3G3iT4')\n",
        "# Function to start ngrok tunnel\n",
        "def start_ngrok():\n",
        "    # Open an ngrok tunnel to the Flask app\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Start ngrok tunnel in a separate thread\n",
        "    threading.Thread(target=start_ngrok, daemon=True).start()\n",
        "\n",
        "    # Run Flask app\n",
        "    app.run(debug=True,port=6000)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "EyrBmvETG9dr",
        "outputId": "549a8a4d-956a-4d09-da6c-281953b33a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:6000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://2f8c-34-16-123-191.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "1",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        }
      ]
    }
  ]
}